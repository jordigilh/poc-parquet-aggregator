name: Test Suite

on:
  push:
    branches: [ main, feature/* ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.12'

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run unit tests
        run: |
          export PYTHONPATH="${PYTHONPATH}:$(pwd)"
          pytest tests/test_storage_aggregator.py -v --tb=short --cov=src.aggregator_storage --cov-report=xml --cov-report=term

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: unit-tests-coverage
          fail_ci_if_error: false

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: koku
          POSTGRES_PASSWORD: koku_test_password
          POSTGRES_DB: koku
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Start MinIO
        run: |
          docker run -d --name minio \
            -p 9000:9000 -p 9001:9001 \
            -e MINIO_ROOT_USER=minioadmin \
            -e MINIO_ROOT_PASSWORD=minioadmin \
            minio/minio:latest server /data --console-address ":9001"
          # Wait for MinIO to be ready
          for i in {1..30}; do
            curl -sf http://localhost:9000/minio/health/live && break
            echo "Waiting for MinIO..."
            sleep 2
          done

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create PostgreSQL schema
        env:
          PGPASSWORD: koku_test_password
        run: |
          psql -h localhost -U koku -d koku -c "CREATE SCHEMA IF NOT EXISTS org1234567;"
          psql -h localhost -U koku -d koku -c "CREATE TABLE IF NOT EXISTS org1234567.reporting_ocpusagelineitem_daily_summary (
            id SERIAL PRIMARY KEY,
            uuid UUID,
            cluster_id VARCHAR(255),
            cluster_alias VARCHAR(255),
            data_source VARCHAR(50),
            namespace VARCHAR(255),
            node VARCHAR(255),
            resource_id VARCHAR(255),
            pod VARCHAR(255),
            persistentvolumeclaim VARCHAR(255),
            persistentvolume VARCHAR(255),
            storageclass VARCHAR(255),
            usage_start DATE,
            usage_end DATE,
            pod_labels JSONB,
            volume_labels JSONB,
            all_labels JSONB,
            pod_usage_cpu_core_hours NUMERIC(24,6),
            pod_request_cpu_core_hours NUMERIC(24,6),
            pod_effective_usage_cpu_core_hours NUMERIC(24,6),
            pod_limit_cpu_core_hours NUMERIC(24,6),
            pod_usage_memory_gigabyte_hours NUMERIC(24,6),
            pod_request_memory_gigabyte_hours NUMERIC(24,6),
            pod_effective_usage_memory_gigabyte_hours NUMERIC(24,6),
            pod_limit_memory_gigabyte_hours NUMERIC(24,6),
            node_capacity_cpu_cores NUMERIC(24,6),
            node_capacity_cpu_core_hours NUMERIC(24,6),
            node_capacity_memory_gigabytes NUMERIC(24,6),
            node_capacity_memory_gigabyte_hours NUMERIC(24,6),
            cluster_capacity_cpu_core_hours NUMERIC(24,6),
            cluster_capacity_memory_gigabyte_hours NUMERIC(24,6),
            persistentvolumeclaim_capacity_gigabyte NUMERIC(24,6),
            persistentvolumeclaim_capacity_gigabyte_months NUMERIC(24,6),
            volume_request_storage_gigabyte_months NUMERIC(24,6),
            persistentvolumeclaim_usage_gigabyte_months NUMERIC(24,6),
            csi_volume_handle VARCHAR(255),
            source_uuid UUID,
            report_period_id INTEGER,
            infrastructure_usage_cost JSONB,
            cost_category_id INTEGER
          );"
          psql -h localhost -U koku -d koku -c "CREATE TABLE IF NOT EXISTS org1234567.reporting_enabledtagkeys (
            id SERIAL PRIMARY KEY,
            key VARCHAR(255),
            enabled BOOLEAN DEFAULT TRUE,
            provider_type VARCHAR(50)
          );"
          psql -h localhost -U koku -d koku -c "INSERT INTO org1234567.reporting_enabledtagkeys (key, enabled, provider_type) VALUES
            ('app', TRUE, 'OCP'),
            ('environment', TRUE, 'OCP'),
            ('version', TRUE, 'OCP')
            ON CONFLICT DO NOTHING;"

      - name: Configure MinIO
        run: |
          wget -q https://dl.min.io/client/mc/release/linux-amd64/mc
          chmod +x mc
          ./mc alias set local http://localhost:9000 minioadmin minioadmin
          ./mc mb local/cost-management --ignore-existing

      - name: Run integration tests
        env:
          PYTHONPATH: ${{ github.workspace }}
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_USER: koku
          POSTGRES_PASSWORD: koku_test_password
          POSTGRES_DB: koku
          POSTGRES_SCHEMA: org1234567
          S3_ENDPOINT: http://localhost:9000
          S3_BUCKET: cost-management
          S3_ACCESS_KEY: minioadmin
          S3_SECRET_KEY: minioadmin
        run: |
          pytest tests/test_storage_integration.py -v --tb=short --cov=src --cov-report=xml --cov-report=term

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: integrationtests
          name: integration-tests-coverage
          fail_ci_if_error: false

  e2e-test:
    name: End-to-End Test with Nise
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: koku
          POSTGRES_PASSWORD: koku_test_password
          POSTGRES_DB: koku
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Start MinIO
        run: |
          docker run -d --name minio \
            -p 9000:9000 -p 9001:9001 \
            -e MINIO_ROOT_USER=minioadmin \
            -e MINIO_ROOT_PASSWORD=minioadmin \
            minio/minio:latest server /data --console-address ":9001"
          # Wait for MinIO to be ready
          for i in {1..30}; do
            curl -sf http://localhost:9000/minio/health/live && break
            echo "Waiting for MinIO..."
            sleep 2
          done

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install koku-nise  # Install nise for data generation

      - name: Create PostgreSQL schema and tables
        env:
          PGPASSWORD: koku_test_password
        run: |
          psql -h localhost -U koku -d koku -c "CREATE SCHEMA IF NOT EXISTS org1234567;"
          psql -h localhost -U koku -d koku -f scripts/create_tables.sql || true
          # Create minimal tables for e2e test
          psql -h localhost -U koku -d koku -c "CREATE TABLE IF NOT EXISTS org1234567.reporting_ocpusagelineitem_daily_summary (
            id SERIAL PRIMARY KEY,
            uuid UUID,
            cluster_id VARCHAR(255),
            cluster_alias VARCHAR(255),
            data_source VARCHAR(50),
            namespace VARCHAR(255),
            node VARCHAR(255),
            resource_id VARCHAR(255),
            pod VARCHAR(255),
            persistentvolumeclaim VARCHAR(255),
            persistentvolume VARCHAR(255),
            storageclass VARCHAR(255),
            usage_start DATE,
            usage_end DATE,
            pod_labels JSONB,
            volume_labels JSONB,
            all_labels JSONB,
            pod_usage_cpu_core_hours NUMERIC(24,6),
            pod_request_cpu_core_hours NUMERIC(24,6),
            pod_effective_usage_cpu_core_hours NUMERIC(24,6),
            pod_limit_cpu_core_hours NUMERIC(24,6),
            pod_usage_memory_gigabyte_hours NUMERIC(24,6),
            pod_request_memory_gigabyte_hours NUMERIC(24,6),
            pod_effective_usage_memory_gigabyte_hours NUMERIC(24,6),
            pod_limit_memory_gigabyte_hours NUMERIC(24,6),
            node_capacity_cpu_cores NUMERIC(24,6),
            node_capacity_cpu_core_hours NUMERIC(24,6),
            node_capacity_memory_gigabytes NUMERIC(24,6),
            node_capacity_memory_gigabyte_hours NUMERIC(24,6),
            cluster_capacity_cpu_core_hours NUMERIC(24,6),
            cluster_capacity_memory_gigabyte_hours NUMERIC(24,6),
            persistentvolumeclaim_capacity_gigabyte NUMERIC(24,6),
            persistentvolumeclaim_capacity_gigabyte_months NUMERIC(24,6),
            volume_request_storage_gigabyte_months NUMERIC(24,6),
            persistentvolumeclaim_usage_gigabyte_months NUMERIC(24,6),
            csi_volume_handle VARCHAR(255),
            source_uuid UUID,
            report_period_id INTEGER,
            infrastructure_usage_cost JSONB,
            cost_category_id INTEGER
          );"
          psql -h localhost -U koku -d koku -c "CREATE TABLE IF NOT EXISTS org1234567.reporting_ocpenabledtagkeys (
            id SERIAL PRIMARY KEY,
            key VARCHAR(255),
            enabled BOOLEAN DEFAULT TRUE,
            provider_type VARCHAR(50)
          );"
          psql -h localhost -U koku -d koku -c "INSERT INTO org1234567.reporting_ocpenabledtagkeys (key, enabled, provider_type) VALUES
            ('app', TRUE, 'OCP'),
            ('environment', TRUE, 'OCP'),
            ('version', TRUE, 'OCP'),
            ('tier', TRUE, 'OCP'),
            ('storage', TRUE, 'OCP')
            ON CONFLICT DO NOTHING;"

      - name: Configure MinIO bucket
        run: |
          wget -q https://dl.min.io/client/mc/release/linux-amd64/mc
          chmod +x mc
          ./mc alias set local http://localhost:9000 minioadmin minioadmin
          ./mc mb local/cost-management --ignore-existing

      - name: Generate test data with nise
        run: |
          mkdir -p e2e_test_data

          # Calculate dates (last month)
          START_DATE=$(date -d "last month" +%Y-%m-01)
          END_DATE=$(date -d "$(date +%Y-%m-01) -1 day" +%Y-%m-%d)

          # Use comprehensive E2E manifest (includes pods + storage + multiple namespaces)
          cp test-manifests/ci-e2e/ci_e2e_manifest.yml e2e_test_data/nise_config.yml

          # Update dates in the config
          sed -i "s/start_date: .*/start_date: $START_DATE/" e2e_test_data/nise_config.yml
          sed -i "s/end_date: .*/end_date: $END_DATE/" e2e_test_data/nise_config.yml

          echo "Generating data for: $START_DATE to $END_DATE"
          echo "Nise config:"
          cat e2e_test_data/nise_config.yml

          # Generate nise data
          nise report ocp \
            --static-report-file e2e_test_data/nise_config.yml \
            --ocp-cluster-id e2e-test-cluster \
            --start-date "$START_DATE" \
            --end-date "$END_DATE" \
            --insights-upload e2e_test_data

          # Find generated CSV directory (nise creates subdirectories)
          echo "Looking for generated files..."
          find e2e_test_data -name "*.csv" -type f 2>/dev/null | head -5
          CSV_DIR=$(find e2e_test_data -type f -name "*.csv" 2>/dev/null | head -1 | xargs dirname 2>/dev/null || echo "")

          if [ -z "$CSV_DIR" ]; then
            echo "❌ No CSV files generated"
            exit 1
          fi

          echo "Generated files in: $CSV_DIR"
          ls -lh "$CSV_DIR"/*.csv

      - name: Convert CSV to Parquet and upload to MinIO
        env:
          PYTHONPATH: ${{ github.workspace }}
          S3_ENDPOINT: http://localhost:9000
          S3_ACCESS_KEY: minioadmin
          S3_SECRET_KEY: minioadmin
          S3_BUCKET: cost-management
          ORG_ID: org1234567
          OCP_PROVIDER_UUID: 00000000-0000-0000-0000-000000000001
          OCP_CLUSTER_ID: e2e-test-cluster
        run: |
          # Find the CSV directory
          CSV_DIR=$(find e2e_test_data -type f -name "*.csv" 2>/dev/null | head -1 | xargs dirname 2>/dev/null)
          CLUSTER_ID="e2e-test-cluster"

          # Get year and month from the generated files
          YEAR=$(date -d "last month" +%Y)
          MONTH=$(date -d "last month" +%m)

          echo "CSV Directory: $CSV_DIR"
          echo "Cluster ID: $CLUSTER_ID"
          echo "Year: $YEAR"
          echo "Month: $MONTH"
          echo "S3 Bucket: $S3_BUCKET"

          # Convert and upload
          python3 scripts/csv_to_parquet_minio.py "$CSV_DIR" $CLUSTER_ID $YEAR $MONTH

          # List what was uploaded to MinIO
          wget -q https://dl.min.io/client/mc/release/linux-amd64/mc -O /tmp/mc
          chmod +x /tmp/mc
          /tmp/mc alias set local http://localhost:9000 minioadmin minioadmin
          echo "Files in MinIO:"
          /tmp/mc ls --recursive local/cost-management/ | head -20

      - name: Run POC aggregation
        env:
          PYTHONPATH: ${{ github.workspace }}
          OCP_CLUSTER_ID: e2e-test-cluster
          OCP_PROVIDER_UUID: 00000000-0000-0000-0000-000000000001
          OCP_YEAR: ${{ steps.get_date.outputs.year }}
          OCP_MONTH: ${{ steps.get_date.outputs.month }}
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_USER: koku
          POSTGRES_PASSWORD: koku_test_password
          POSTGRES_DB: koku
          POSTGRES_SCHEMA: org1234567
          S3_ENDPOINT: http://localhost:9000
          S3_BUCKET: cost-management
          S3_ACCESS_KEY: minioadmin
          S3_SECRET_KEY: minioadmin
          ORG_ID: org1234567
          LOG_LEVEL: INFO
        run: |
          # Get current year and last month for env vars
          export OCP_YEAR=$(date -d "last month" +%Y)
          export OCP_MONTH=$(date -d "last month" +%m)

          echo "Running POC with:"
          echo "  Cluster ID: $OCP_CLUSTER_ID"
          echo "  Provider UUID: $OCP_PROVIDER_UUID"
          echo "  Year: $OCP_YEAR"
          echo "  Month: $OCP_MONTH"

          # Run POC
          python3 -m src.main --truncate 2>&1 | tee e2e_poc_output.log

          # Check for success
          if grep -q "POC COMPLETED SUCCESSFULLY" e2e_poc_output.log; then
            echo "✅ POC completed successfully"
          else
            echo "❌ POC failed"
            exit 1
          fi

      - name: Validate results
        env:
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_USER: koku
          POSTGRES_PASSWORD: koku_test_password
          POSTGRES_DB: koku
          ORG_ID: org1234567
        run: |
          # Use shared validation script for consistency with local E2E tests
          chmod +x scripts/validate_e2e_results.sh
          ./scripts/validate_e2e_results.sh e2e-test-cluster

      - name: Upload POC logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-poc-logs
          path: |
            e2e_poc_output.log
            e2e_test_data/*.csv
          retention-days: 7

  # Future: OCP-in-AWS E2E Test
  # Will be added when OCP-in-AWS implementation is complete
  # e2e-test-ocp-aws:
  #   name: End-to-End Test - OCP on AWS
  #   runs-on: ubuntu-latest
  #   steps:
  #     - Generate OCP data with nise
  #     - Generate AWS CUR data with nise
  #     - Run POC with OCP-in-AWS aggregation
  #     - Validate resource ID matching
  #     - Validate tag-based matching
  #     - Validate cost attribution

  summary:
    name: Test Summary
    needs: [unit-tests, integration-tests, e2e-test]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Check test results
        run: |
          echo "=== Test Suite Summary ==="
          echo "Unit Tests: ${{ needs.unit-tests.result }}"
          echo "Integration Tests: ${{ needs.integration-tests.result }}"
          echo "E2E Test: ${{ needs.e2e-test.result }}"

          if [ "${{ needs.unit-tests.result }}" != "success" ] || \
             [ "${{ needs.integration-tests.result }}" != "success" ] || \
             [ "${{ needs.e2e-test.result }}" != "success" ]; then
            echo "❌ Some tests failed"
            exit 1
          else
            echo "✅ All tests passed!"
          fi

