#!/usr/bin/env python3
"""
Validate POC output columns against Koku database schema.

This script catches column mismatches BEFORE attempting to write,
preventing bugs like #7 (pod vs resource_id) and #8 (csi_volume_handle).

Usage:
    # With database connection:
    python scripts/validate_koku_schema.py --host localhost --port 15432 --schema org1234567

    # Dry run (just show POC output columns):
    python scripts/validate_koku_schema.py --dry-run
"""

import argparse
import sys
from typing import Dict, List, Set

# POC output columns (must match what aggregators produce)
POC_OCP_SUMMARY_COLUMNS = [
    "uuid",
    "report_period_id",
    "cluster_id",
    "cluster_alias",
    "data_source",
    "usage_start",
    "usage_end",
    "namespace",
    "node",
    "resource_id",  # NOT "pod" - Bug #7 fix
    "pod_labels",
    "pod_usage_cpu_core_hours",
    "pod_request_cpu_core_hours",
    "pod_effective_usage_cpu_core_hours",
    "pod_limit_cpu_core_hours",
    "pod_usage_memory_gigabyte_hours",
    "pod_request_memory_gigabyte_hours",
    "pod_effective_usage_memory_gigabyte_hours",
    "pod_limit_memory_gigabyte_hours",
    "node_capacity_cpu_cores",
    "node_capacity_cpu_core_hours",
    "node_capacity_memory_gigabytes",
    "node_capacity_memory_gigabyte_hours",
    "cluster_capacity_cpu_core_hours",
    "cluster_capacity_memory_gigabyte_hours",
    "persistentvolumeclaim",
    "persistentvolume",
    "storageclass",
    "volume_labels",
    "all_labels",
    "persistentvolumeclaim_capacity_gigabyte",
    "persistentvolumeclaim_capacity_gigabyte_months",
    "volume_request_storage_gigabyte_months",
    "persistentvolumeclaim_usage_gigabyte_months",
    "source_uuid",
    "infrastructure_usage_cost",
    # "csi_volume_handle",  # REMOVED - Bug #8 fix
    "cost_category_id",
]

# Known columns that should NOT be in POC output (Bug fixes)
FORBIDDEN_COLUMNS = {
    "pod": "Bug #7 - Use 'resource_id' instead",
    "csi_volume_handle": "Bug #8 - Column does not exist in Koku DB",
}


def get_koku_table_columns(host: str, port: int, database: str, user: str, password: str, schema: str, table: str) -> Set[str]:
    """Get column names from Koku database."""
    import psycopg2
    
    conn = psycopg2.connect(
        host=host,
        port=port,
        database=database,
        user=user,
        password=password,
    )
    
    try:
        with conn.cursor() as cursor:
            cursor.execute("""
                SELECT column_name
                FROM information_schema.columns
                WHERE table_schema = %s AND table_name = %s
            """, (schema, table))
            columns = {row[0] for row in cursor.fetchall()}
        return columns
    finally:
        conn.close()


def validate_columns(poc_columns: List[str], db_columns: Set[str], table_name: str) -> Dict[str, List[str]]:
    """Validate POC columns against database schema."""
    poc_set = set(poc_columns)
    
    # Find mismatches
    invalid_in_poc = poc_set - db_columns - {"uuid"}  # uuid is generated by DB
    missing_from_poc = db_columns - poc_set
    
    # Check for forbidden columns
    forbidden_found = {col: reason for col, reason in FORBIDDEN_COLUMNS.items() if col in poc_set}
    
    return {
        "invalid_in_poc": list(invalid_in_poc),
        "missing_from_poc": list(missing_from_poc),
        "forbidden_found": forbidden_found,
    }


def main():
    parser = argparse.ArgumentParser(description="Validate POC columns against Koku DB schema")
    parser.add_argument("--host", default="localhost", help="Database host")
    parser.add_argument("--port", type=int, default=15432, help="Database port")
    parser.add_argument("--database", default="koku", help="Database name")
    parser.add_argument("--user", default="postgres", help="Database user")
    parser.add_argument("--password", default="postgres", help="Database password")
    parser.add_argument("--schema", default="org1234567", help="Database schema")
    parser.add_argument("--dry-run", action="store_true", help="Just show POC columns, don't connect to DB")
    args = parser.parse_args()
    
    print("=" * 80)
    print("POC Schema Validation Against Koku Database")
    print("=" * 80)
    
    # Check for forbidden columns first
    print("\nüìã Checking for forbidden columns (known bugs)...")
    poc_set = set(POC_OCP_SUMMARY_COLUMNS)
    forbidden_found = {col: reason for col, reason in FORBIDDEN_COLUMNS.items() if col in poc_set}
    
    if forbidden_found:
        print("\n‚ùå FORBIDDEN COLUMNS FOUND IN POC OUTPUT:")
        for col, reason in forbidden_found.items():
            print(f"   - '{col}': {reason}")
        print("\n‚ö†Ô∏è  These columns must be removed from aggregator output!")
        sys.exit(1)
    else:
        print("   ‚úÖ No forbidden columns found")
    
    print(f"\nüìã POC OCP Summary Columns ({len(POC_OCP_SUMMARY_COLUMNS)} total):")
    for i, col in enumerate(POC_OCP_SUMMARY_COLUMNS, 1):
        print(f"   {i:2d}. {col}")
    
    if args.dry_run:
        print("\n‚è≠Ô∏è  Dry run - skipping database validation")
        print("   Run with database connection to validate against actual schema")
        sys.exit(0)
    
    # Connect to database and validate
    print(f"\nüîó Connecting to {args.host}:{args.port}/{args.database}...")
    
    try:
        table_name = "reporting_ocpusagelineitem_daily_summary"
        db_columns = get_koku_table_columns(
            args.host, args.port, args.database, args.user, args.password, args.schema, table_name
        )
        
        print(f"   ‚úÖ Connected! Found {len(db_columns)} columns in {args.schema}.{table_name}")
        
        # Validate
        print(f"\nüîç Validating POC columns against database schema...")
        results = validate_columns(POC_OCP_SUMMARY_COLUMNS, db_columns, table_name)
        
        errors = False
        
        if results["invalid_in_poc"]:
            print(f"\n‚ùå COLUMNS IN POC BUT NOT IN DATABASE ({len(results['invalid_in_poc'])}):")
            for col in sorted(results["invalid_in_poc"]):
                print(f"   - '{col}' ‚Üê REMOVE from aggregator output!")
            errors = True
        
        if results["missing_from_poc"]:
            print(f"\n‚ö†Ô∏è  COLUMNS IN DATABASE BUT NOT IN POC ({len(results['missing_from_poc'])}):")
            for col in sorted(results["missing_from_poc"]):
                print(f"   - '{col}' (may be optional)")
        
        if errors:
            print("\n" + "=" * 80)
            print("‚ùå VALIDATION FAILED - Fix the issues above before deploying!")
            print("=" * 80)
            sys.exit(1)
        else:
            print("\n" + "=" * 80)
            print("‚úÖ VALIDATION PASSED - All POC columns exist in database!")
            print("=" * 80)
            sys.exit(0)
            
    except Exception as e:
        print(f"\n‚ùå Database connection failed: {e}")
        print("   Make sure you can connect to the Koku database")
        sys.exit(1)


if __name__ == "__main__":
    main()

